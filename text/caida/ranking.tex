\section{State Rankings}

Using the statistical and (in)distinguishability graph methods described in \cref{sec:stats_methods}, we were able to develop both graph visualizations of state distinguishability and a possible ranking of the states.

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.65\textwidth]{caida/caida_network_invalid_comps.png}
    \caption{Indistinguishability graph of traceroute data as aggregated by state}
    \label{fig:caida_network_invalid_comps}
\end{figure}

\Cref{fig:caida_network_invalid_comps} shows an indistinguishability graph of comparisons between the states (previously seen in \cref{sec:stats_methods}), where node colors correspond to communities and bold red lines correspond to bridges.\footnote{Bridges can be thought of as indicators of comparison quality; any state on the end of a bridge can be compared to all but one of the other states.} As noted earlier, this graph has no disjoint subgraphs, so ranking by clusters is not possible. \Cref{fig:caida_network_valid_comps} shows the corresponding distinguishability graph, which is much more connected, indicating this data is a good candidate for the topological sort method.

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.65\textwidth]{caida/caida_network_valid_comps.png}
    \caption{Distinguishability graph of traceroute data as aggregated by state}
    \label{fig:caida_network_valid_comps}
\end{figure}

When sorted we obtain a list of 49 states (including the District of Columbia; Hawaii and Alaska were unreachable); two states were not reachable by a maximal topological sort (described in \cref{sec:methods_stats_topological_rankings}). \Cref{tab:caida_topological_state_rankings} shows this ranking, which roughly confirms what we would expect based on prior notions and the heatmaps. Since the topological sort method is based on a graph interpretation and not a traditional sort of means or medians, those values are not shown alongside the states.

\input{text/caida/tables/topological_state_ranks.tex}

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{images/comparative/confidence_intervals/caida_confidence_interval.png}
    \caption{Traceroute confidence intervals for rankings; higher is better}
    \label{fig:caida_confidence_intervals}
\end{figure}

\Cref{fig:caida_confidence_intervals} shows an alternate way of displaying state ranks, using the mean of each state for comparisons. Since data for each state does not follow a normal distribution (see \cref{sec:comparative-distribution} for a variety of \kdes on the subject) the bootstrapping method was used to calculate confidence intervals. Loosely speaking, for each state the "true" mean could be anywhere between the upper and lower bounds of the intervals. \Cref{tab:traceroute_confidence_intervals} shows the specific values for each of these points.

\input{text/caida/tables/caida_confidence_intervals}

The confidence intervals for each state's mean are large, indicating that there are few meaningful comparisons to be made here. The same conclusion can be drawn from the indistinguishability graph in \cref{fig:caida_network_invalid_comps}; there are no disjoint subgraphs so a ranking by groups of states cannot even be drawn. The topological sorting results shown in \cref{tab:caida_topological_state_rankings} are interesting but they have the fundamental flaw of topological sorts as described in \cref{sec:methods_stats_topological_rankings}: the sorting relies on implicit comparisons that cannot be made according to this data set.

The underlying problem is not with variance in the data itself (as shown by \cref{fig:caida_cv_distribution} and \cref{fig:caida_stdev_distribution} the data spread is low, proving quality data), but in the aggregation method. As visualized in \cref{fig:caida_idw_heatmap} there is simply too much variation within a state, prohibiting a statistically-valid ranking of all 50 of them. We can make simple assertions where confidence intervals do not overlap, or between two states where $p<0.05$, but unfortunately nothing beyond that.

The conclusions that we \textit{can} draw on a state level are that, loosely speaking, states that are more populated or more urban tend to have better internet than those are are less populated or more rural on average. The District of Columbia, being only a city and also the seat of the \us federal government, has the best internet. On the other hand, sparsely populated states like Montana or North Dakota rank at absolute last. To get an accurate idea of internet connectivity, the only statistically-valid choice is to use aggregation by a narrower area, or a continuous interpolation method like the \idw heatmap in \cref{fig:caida_idw_heatmap}.
